# MONAI 3D Latent Diffusion Model Configuration
# 用于点云体素生成的完整配置文件

# 数据配置
data:
  # 训练和验证数据路径
  train_data_dir: "/repos/datasets/batch_simulation_microtubule_20251017_2048_nifti/train"
  val_data_dir: "/repos/datasets/batch_simulation_microtubule_20251017_2048_nifti/val"
  
  # 体素分辨率（训练时的目标分辨率）
  # 可以是单个整数（各向同性）或列表[X, Y, Z]（各向异性）
  # 例如: 64 或 [64, 64, 32] 或 [256, 256, 64]
  # 注意: 分辨率越大，显存占用越高，建议配合混合精度训练和梯度累积使用
  voxel_size: [96, 96, 48]  # [X, Y, Z]
  
  # 预处理resize分辨率（在裁剪前先resize到此分辨率）
  # null表示不进行预resize，直接使用原始分辨率进行后续处理
  # 如果设置了值，则会在Spacing后先resize到此分辨率，再进行裁剪
  # 可以是单个整数（各向同性）或列表[X, Y, Z]（各向异性）
  # 例如: 128 或 [128, 128, 64] 或 null
  voxel_resize: [128, 128, 64]  # 预处理resize，null表示不进行预resize
  
  # 数据加载设置
  cache_rate: 0.2  # 缓存比例，0表示不缓存，1表示全部缓存
  num_workers: 4
  pin_memory: false
  max_data_size_for_train: 100
  max_data_size_for_val: 4
  
  # 数据增强
  augmentation:
    enabled: true
    use_patch_based: false  # ⭐ 启用Patch-Based训练
    use_center_crop_for_val: true  # 验证时使用中心裁剪
    invert_intensity: false  # 是否对图片亮度进行反转（将最小亮度变成最大，最大亮度变成最小）
    # random_flip_prob: 0.5
    # random_rotate_prob: 0.5

# AutoencoderKL 配置
autoencoder:
  # 网络架构
  spatial_dims: 3
  in_channels: 1
  out_channels: 1
  # 注意: num_channels越大，显存占用越高
  # 对于高分辨率（如256x256x64），建议使用较小的通道数，如[16, 32, 64]
  # 对于低分辨率（如64x64x32），可以使用较大的通道数，如[32, 64, 64]
  num_channels: [32, 64, 128]
  latent_channels: 16
  num_res_blocks: 1
  norm_num_groups: 16
  # attention_levels: 注意力机制非常占显存，建议只在最后一层使用
  attention_levels: [false, false, true]
  
  # 下采样因子配置 (新增功能)
  # downsample_factors: 每层之间的下采样倍数，长度应该是 len(num_channels) - 1
  # 例如: [2, 2] 表示两次下采样，总共4倍 (默认)
  #       [4, 2] 表示第一层下采样4倍，第二层2倍，总共8倍
  #       [2, 4] 表示第一层下采样2倍，第二层4倍，总共8倍
  #       [8] 表示一次下采样8倍（需要num_channels只有2个元素）
  downsample_factors: [2, 2]  # 默认4倍总下采样
  # downsample_factors: [4, 2]  # 8倍总下采样（推荐用于256x256x64）
  # downsample_factors: [8, 2]  # 16倍总下采样（推荐用于512x512x128）
  
  # ⭐ 初始下采样因子 (新增功能)
  # initial_downsample_factor: Initial Conv的下采样倍数，在第0层之前就开始下采样
  # 这样可以更早地减小特征图尺寸，进一步节省显存！
  # 总下采样倍数 = initial_downsample_factor × downsample_factors的乘积
  # 例如: initial_downsample_factor=2, downsample_factors=[4, 2] → 总共2×4×2=16倍
  initial_downsample_factor: 1  # 默认1（不下采样，向后兼容）
  # initial_downsample_factor: 2  # 初始2倍下采样（推荐用于256x256x64）
  # initial_downsample_factor: 4  # 初始4倍下采样（推荐用于512x512x128）
  
  # ⭐ 下采样方法 (新增功能)
  # use_conv_downsample: 是否使用卷积下采样
  # true: 使用步幅卷积（可学习参数，表达能力更强，但参数量更多）
  # false: 使用平均池化（无可学习参数，速度更快，显存占用更少，平滑性更好）
  # use_conv_downsample: true  # 默认true（使用卷积，向后兼容）
  use_conv_downsample: true  # 使用平均池化（推荐用于节省显存和加速训练）
  
  # ⭐ 上采样方法 (新增功能)
  # use_convtranspose: 是否使用转置卷积上采样
  # true: 使用转置卷积（可学习参数，表达能力更强，可能产生棋盘效应）
  # false: 使用最近邻插值+卷积（默认方式，平滑性更好，无棋盘效应）
  # use_convtranspose: false  # 默认false（使用插值，向后兼容）
  use_convtranspose: true  # 使用转置卷积（与下采样方式对称）
  
  # 训练配置
  training:
    n_epochs: 500
    batch_size: 1  # 对于256x256x64，建议batch_size=1或2
    learning_rate: 1.0e-4
    
    # 损失权重
    adv_weight: 0.01
    perceptual_weight: 0.001
    kl_weight: 1.0e-6
    
    # 显存优化选项
    use_perceptual_loss: false  # 对于高分辨率，可以设为false以节省显存
    use_gradient_checkpointing: true  # 启用梯度检查点，可节省显存但会增加训练时间
    gradient_accumulation_steps: 1  # 梯度累积步数，增大可模拟更大的batch size
    
    # 对抗训练
    autoencoder_warm_up_n_epochs: 599  # 前N个epoch不使用对抗损失
    
    # ==================== 去噪自编码器配置 ====================
    # 启用去噪自编码器模式，让模型学习从噪声中恢复干净图像
    # 这样可以迫使模型学习数据的深层特征，而不是简单地复制输入
    denoising:
      enabled: true  # 是否启用去噪模式
      noise_type: "mixed"  # 噪声类型: "gaussian", "dropout", "mixed"
      noise_std: 0.03  # 高斯噪声标准差（对于[0, 1]归一化的图像）
      dropout_prob: 0.1  # 体素丢弃概率
      # 
      # 噪声类型说明:
      # - gaussian: 添加高斯噪声，适合模拟传感器噪声
      # - dropout: 随机将一些体素置零，适合模拟数据缺失
      # - mixed: 同时应用gaussian和dropout，更具挑战性
      # 
      # 参数调节建议（注意：数据归一化到[0, 1]范围）:
      # - 初期训练: noise_std=0.1, dropout_prob=0.05 (较温和)
      # - 进阶训练: noise_std=0.15, dropout_prob=0.1 (中等难度，推荐)
      # - 高难度: noise_std=0.2, dropout_prob=0.15 (更具挑战性)
    
    # 判别器配置
    discriminator:
      num_layers_d: 3
      num_channels: 32
    
    # 验证和保存
    val_interval: 5  # 每N个epoch进行验证
    save_interval: 10  # 每N个epoch保存checkpoint
    
    # 快速开发模式
    fast_dev_run: false  # 如果为true，只运行少量batch用于调试
    fast_dev_run_batches: 2  # fast_dev_run模式下每个epoch运行的batch数
    
  # Checkpoint路径
  checkpoints:
    output_dir: "outputs/ckpt/autoencoder"
    save_best: true  # 是否保存最佳模型
    resume_from: null  # 恢复训练的checkpoint路径，null表示从头开始
  
  # 日志配置
  logging:
    log_dir: "outputs/logs/autoencoder"
    log_interval: 10  # 每N个batch记录一次日志
    visualize_interval: 2  # 每N个epoch可视化一次重建结果
    num_visualize_samples: 4  # 可视化的样本数量
    
    # 滑动窗口推理配置（用于可视化完整图像重建）
    use_sliding_window: false  # 是否启用滑动窗口推理进行可视化
    sliding_window_roi_size: null  # ROI大小，null表示自动使用训练patch大小
    sliding_window_batch_size: 1  # 滑动窗口推理的批次大小（如果内存不足，可降到1）

# Diffusion Model 配置
diffusion:
  # UNet架构
  spatial_dims: 3
  in_channels: 3  # 必须匹配autoencoder的latent_channels
  out_channels: 3
  num_channels: [32, 64, 64]
  attention_levels: [false, true, true]
  num_head_channels: [0, 64, 64]
  num_res_blocks: 1
  
  # 调度器配置
  scheduler:
    num_train_timesteps: 1000
    schedule: "scaled_linear_beta"
    beta_start: 0.0015
    beta_end: 0.0195
  
  # 训练配置
  training:
    n_epochs: 500
    batch_size: 2
    learning_rate: 1.0e-4
    
    # 验证和保存
    val_interval: 10
    save_interval: 50
    
    # 样本生成
    generate_samples_interval: 10  # 每N个epoch生成样本用于监控
    num_samples_to_generate: 4  # 生成的样本数量
    
    # 快速开发模式
    fast_dev_run: true
    fast_dev_run_batches: 2
  
  # Checkpoint路径
  checkpoints:
    autoencoder_path: "outputs/ckpt/autoencoder/best_model.pt"  # 预训练的autoencoder
    output_dir: "outputs/ckpt/diffusion"
    save_best: true
    resume_from: null
  
  # 日志配置
  logging:
    log_dir: "outputs/logs/diffusion"
    log_interval: 20
    visualize_interval: 10  # 每N个epoch可视化一次生成样本与真实样本的对比
    num_visualize_samples: 4  # 可视化的样本数量

# 采样配置
sampling:
  num_inference_steps: 1000  # DDPM采样步数
  num_samples: 16  # 一次生成的样本数量
  
  # 输出配置
  output_dir: "outputs/samples/diffusion"
  save_format: "nifti"  # "nifti" 或 "pointcloud"
  
  # 点云转换配置（如果save_format包含pointcloud）
  pointcloud:
    num_points: 100000
    threshold: 0.1
    method: "probabilistic"  # "probabilistic", "center", "random", "weighted"

# 设备配置
device:
  use_cuda: true
  gpu_id: 0  # 使用的GPU ID
  mixed_precision: true  # 是否使用混合精度训练（强烈建议启用，可节省约50%显存）

# 随机种子
seed: 42

