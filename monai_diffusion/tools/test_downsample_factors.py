"""
æµ‹è¯•AutoencoderKLçš„downsample_factorsåŠŸèƒ½

éªŒè¯ä¸åŒä¸‹é‡‡æ ·å› å­é…ç½®ä¸‹çš„æ¨¡å‹åˆ›å»ºå’Œå‰å‘ä¼ æ’­ã€‚
"""

import sys
from pathlib import Path

# æ·»åŠ GenerativeModelsåˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root / "GenerativeModels"))

import torch
from generative.networks.nets import AutoencoderKL
import numpy as np


def test_downsample_factor_config(
    input_size=(64, 64, 32),
    num_channels=(32, 64, 64),
    downsample_factors=None,
    initial_downsample_factor=1,
    batch_size=2
):
    """
    æµ‹è¯•æŒ‡å®šä¸‹é‡‡æ ·å› å­é…ç½®
    
    Args:
        input_size: è¾“å…¥ä½“ç´ å¤§å° (H, W, D)
        num_channels: æ¯å±‚é€šé“æ•°
        downsample_factors: ä¸‹é‡‡æ ·å› å­åˆ—è¡¨
        initial_downsample_factor: åˆå§‹ä¸‹é‡‡æ ·å› å­
        batch_size: æ‰¹æ¬¡å¤§å°
    """
    print(f"\n{'='*60}")
    print(f"æµ‹è¯•é…ç½®:")
    print(f"  è¾“å…¥å¤§å°: {input_size}")
    print(f"  num_channels: {num_channels}")
    print(f"  initial_downsample_factor: {initial_downsample_factor}")
    print(f"  downsample_factors: {downsample_factors}")
    print(f"  batch_size: {batch_size}")
    print(f"{'='*60}")
    
    # è®¡ç®—æ€»ä¸‹é‡‡æ ·å€æ•°
    if downsample_factors is None:
        total_downsample = initial_downsample_factor * (2 ** (len(num_channels) - 1))
        print(f"âœ“ ä½¿ç”¨é»˜è®¤é…ç½®: æ€»ä¸‹é‡‡æ · {total_downsample}x")
    else:
        total_downsample = initial_downsample_factor * np.prod(downsample_factors)
        print(f"âœ“ ä½¿ç”¨è‡ªå®šä¹‰é…ç½®: æ€»ä¸‹é‡‡æ · {total_downsample}x")
    
    # è®¡ç®—é¢„æœŸlatentå¤§å°
    expected_latent_size = tuple(int(s / total_downsample) for s in input_size)
    print(f"âœ“ é¢„æœŸLatentå¤§å°: {expected_latent_size}")
    
    try:
        # åˆ›å»ºæ¨¡å‹
        model = AutoencoderKL(
            spatial_dims=3,
            in_channels=1,
            out_channels=1,
            num_channels=num_channels,
            latent_channels=3,
            num_res_blocks=1,
            norm_num_groups=16,
            attention_levels=tuple([False] * (len(num_channels) - 1) + [True]),
            downsample_factors=downsample_factors,
            initial_downsample_factor=initial_downsample_factor
        )
        print(f"âœ“ æ¨¡å‹åˆ›å»ºæˆåŠŸ")
        
        # ç»Ÿè®¡å‚æ•°é‡
        total_params = sum(p.numel() for p in model.parameters())
        print(f"âœ“ å‚æ•°é‡: {total_params:,}")
        
        # åˆ›å»ºéšæœºè¾“å…¥
        x = torch.randn(batch_size, 1, *input_size)
        print(f"âœ“ åˆ›å»ºè¾“å…¥å¼ é‡: {x.shape}")
        
        # å‰å‘ä¼ æ’­
        with torch.no_grad():
            # Encoder
            z = model.encode(x)
            z_mu, z_sigma = z
            print(f"âœ“ Encoderè¾“å‡º: z_mu={z_mu.shape}, z_sigma={z_sigma.shape}")
            
            # é‡‡æ ·
            z_sample = model.sampling(z_mu, z_sigma)
            print(f"âœ“ é‡‡æ ·è¾“å‡º: {z_sample.shape}")
            
            # Decoder
            reconstruction = model.decode(z_sample)
            print(f"âœ“ Decoderè¾“å‡º: {reconstruction.shape}")
            
            # å®Œæ•´å‰å‘ä¼ æ’­
            output, z_mu_full, z_sigma_full = model(x)
            print(f"âœ“ å®Œæ•´å‰å‘ä¼ æ’­: {output.shape}")
        
        # éªŒè¯è¾“å‡ºå½¢çŠ¶
        assert output.shape == x.shape, f"è¾“å‡ºå½¢çŠ¶ä¸åŒ¹é…: {output.shape} vs {x.shape}"
        assert z_mu.shape[2:] == expected_latent_size, \
            f"Latentå¤§å°ä¸åŒ¹é…: {z_mu.shape[2:]} vs {expected_latent_size}"
        
        print(f"\n{'âœ… æµ‹è¯•é€šè¿‡!'}")
        
        # ä¼°ç®—æ˜¾å­˜å ç”¨ï¼ˆç²—ç•¥ï¼‰
        input_memory = np.prod(x.shape) * 4 / 1024 / 1024  # MB
        latent_memory = np.prod(z_mu.shape) * 4 / 1024 / 1024  # MB
        compression_ratio = input_memory / latent_memory
        
        print(f"\næ˜¾å­˜åˆ†æ:")
        print(f"  è¾“å…¥æ•°æ®: {input_memory:.2f} MB")
        print(f"  Latentç©ºé—´: {latent_memory:.2f} MB")
        print(f"  å‹ç¼©æ¯”: {compression_ratio:.1f}x")
        
        return True
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\n" + "="*60)
    print("AutoencoderKLä¸‹é‡‡æ ·å› å­åŠŸèƒ½æµ‹è¯•")
    print("="*60)
    
    results = []
    
    # æµ‹è¯•1: é»˜è®¤é…ç½®ï¼ˆå‘åå…¼å®¹ï¼‰
    print("\nã€æµ‹è¯•1ã€‘é»˜è®¤é…ç½® - å‘åå…¼å®¹æ€§")
    results.append(test_downsample_factor_config(
        input_size=(64, 64, 32),
        num_channels=(32, 64, 64),
        downsample_factors=None,  # é»˜è®¤ [2, 2]
        batch_size=2
    ))
    
    # æµ‹è¯•2: 8å€ä¸‹é‡‡æ · [4, 2]
    print("\nã€æµ‹è¯•2ã€‘8å€ä¸‹é‡‡æ · - æ¨èé…ç½®")
    results.append(test_downsample_factor_config(
        input_size=(256, 256, 64),
        num_channels=(16, 32, 64),
        downsample_factors=[4, 2],
        batch_size=1
    ))
    
    # æµ‹è¯•3: 16å€ä¸‹é‡‡æ · [8, 2]
    print("\nã€æµ‹è¯•3ã€‘16å€ä¸‹é‡‡æ · - è¶…é«˜åˆ†è¾¨ç‡")
    results.append(test_downsample_factor_config(
        input_size=(512, 512, 128),
        num_channels=(16, 32, 64),
        downsample_factors=[8, 2],
        batch_size=1
    ))
    
    # æµ‹è¯•4: 16å€ä¸‹é‡‡æ · [4, 4]
    print("\nã€æµ‹è¯•4ã€‘16å€ä¸‹é‡‡æ · - å‡è¡¡é…ç½®")
    results.append(test_downsample_factor_config(
        input_size=(256, 256, 64),
        num_channels=(32, 64, 64),
        downsample_factors=[4, 4],
        batch_size=1
    ))
    
    # æµ‹è¯•5: å•å±‚å¤§ä¸‹é‡‡æ · [16]
    print("\nã€æµ‹è¯•5ã€‘å•å±‚16å€ä¸‹é‡‡æ · - æç®€é…ç½®")
    results.append(test_downsample_factor_config(
        input_size=(256, 256, 64),
        num_channels=(32, 64),  # åªæœ‰2å±‚
        downsample_factors=[16],
        batch_size=1
    ))
    
    # æµ‹è¯•6: 4å±‚ç½‘ç»œ
    print("\nã€æµ‹è¯•6ã€‘4å±‚ç½‘ç»œ - 32å€ä¸‹é‡‡æ ·")
    results.append(test_downsample_factor_config(
        input_size=(512, 512, 128),
        num_channels=(16, 32, 64, 128),
        downsample_factors=[4, 4, 2],
        batch_size=1
    ))
    
    # æµ‹è¯•7: ä½¿ç”¨Initial Downsample - 16å€ä¸‹é‡‡æ ·
    print("\nã€æµ‹è¯•7ã€‘Initial Downsample=2 - 16å€ä¸‹é‡‡æ ·")
    results.append(test_downsample_factor_config(
        input_size=(256, 256, 64),
        num_channels=(32, 64, 64),
        downsample_factors=[4, 2],
        initial_downsample_factor=2,  # â­ æ–°åŠŸèƒ½
        batch_size=1
    ))
    
    # æµ‹è¯•8: ä½¿ç”¨Initial Downsample - 32å€ä¸‹é‡‡æ ·
    print("\nã€æµ‹è¯•8ã€‘Initial Downsample=4 - 32å€ä¸‹é‡‡æ ·")
    results.append(test_downsample_factor_config(
        input_size=(512, 512, 128),
        num_channels=(16, 32, 64),
        downsample_factors=[4, 2],
        initial_downsample_factor=4,  # â­ æ›´æ¿€è¿›
        batch_size=1
    ))
    
    # æµ‹è¯•9: æè‡´Initial Downsample - 64å€ä¸‹é‡‡æ ·
    print("\nã€æµ‹è¯•9ã€‘Initial Downsample=8 - 64å€ä¸‹é‡‡æ ·")
    results.append(test_downsample_factor_config(
        input_size=(512, 512, 128),
        num_channels=(16, 32, 64),
        downsample_factors=[4, 2],
        initial_downsample_factor=8,  # â­ æè‡´å‹ç¼©
        batch_size=1
    ))
    
    # æ€»ç»“
    print("\n" + "="*60)
    print("æµ‹è¯•æ€»ç»“")
    print("="*60)
    total = len(results)
    passed = sum(results)
    failed = total - passed
    
    print(f"æ€»æµ‹è¯•æ•°: {total}")
    print(f"é€šè¿‡: {passed} âœ…")
    print(f"å¤±è´¥: {failed} âŒ")
    
    if failed == 0:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼åŠŸèƒ½æ­£å¸¸å·¥ä½œã€‚")
    else:
        print(f"\nâš ï¸  æœ‰ {failed} ä¸ªæµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®ã€‚")
    
    return failed == 0


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)

