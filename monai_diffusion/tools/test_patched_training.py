"""
æµ‹è¯•Patch-Basedè®­ç»ƒé…ç½®

éªŒè¯æ–°çš„patch-basedè®­ç»ƒé…ç½®æ˜¯å¦èƒ½æ­£å¸¸å·¥ä½œã€‚
"""

import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root / "GenerativeModels"))
sys.path.insert(0, str(project_root))

import torch
import yaml
from monai.utils import set_determinism
import logging

from generative.networks.nets import AutoencoderKL, PatchDiscriminator
from monai_diffusion.datasets import create_train_val_dataloaders
from monai_diffusion.utils import AutoencoderSlidingWindowInferer

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def test_data_loading(config_path: str):
    """æµ‹è¯•æ•°æ®åŠ è½½"""
    logger.info("=" * 60)
    logger.info("æµ‹è¯•1: æ•°æ®åŠ è½½")
    logger.info("=" * 60)
    
    with open(config_path, 'r') as f:
        config = yaml.safe_load(f)
    
    try:
        # å°è¯•åˆ›å»ºæ•°æ®åŠ è½½å™¨
        logger.info("åˆ›å»ºè®­ç»ƒå’ŒéªŒè¯æ•°æ®åŠ è½½å™¨...")
        train_loader, val_loader = create_train_val_dataloaders(config)
        
        logger.info(f"âœ… æ•°æ®åŠ è½½å™¨åˆ›å»ºæˆåŠŸ")
        logger.info(f"   è®­ç»ƒé›†å¤§å°: {len(train_loader.dataset)}")
        logger.info(f"   éªŒè¯é›†å¤§å°: {len(val_loader.dataset)}")
        logger.info(f"   Batchå¤§å°: {train_loader.batch_size}")
        
        # å°è¯•åŠ è½½ä¸€ä¸ªbatch
        logger.info("åŠ è½½ä¸€ä¸ªè®­ç»ƒbatch...")
        batch = next(iter(train_loader))
        logger.info(f"âœ… BatchåŠ è½½æˆåŠŸ")
        logger.info(f"   å›¾åƒå½¢çŠ¶: {batch['image'].shape}")
        logger.info(f"   æ•°æ®ç±»å‹: {batch['image'].dtype}")
        logger.info(f"   æ•°å€¼èŒƒå›´: [{batch['image'].min():.3f}, {batch['image'].max():.3f}]")
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯æœŸæœ›çš„patchå¤§å°
        expected_size = tuple(config['data']['voxel_size'])
        actual_size = tuple(batch['image'].shape[2:])  # (B, C, H, W, D)
        
        if actual_size == expected_size:
            logger.info(f"âœ… Patchå¤§å°æ­£ç¡®: {actual_size}")
        else:
            logger.warning(f"âš ï¸ Patchå¤§å°ä¸åŒ¹é…: æœŸæœ›{expected_size}, å®é™…{actual_size}")
        
        return True, train_loader, val_loader
        
    except Exception as e:
        logger.error(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False, None, None


def test_model_creation(config_path: str):
    """æµ‹è¯•æ¨¡å‹åˆ›å»º"""
    logger.info("\n" + "=" * 60)
    logger.info("æµ‹è¯•2: æ¨¡å‹åˆ›å»º")
    logger.info("=" * 60)
    
    with open(config_path, 'r') as f:
        config = yaml.safe_load(f)
    
    ae_config = config['autoencoder']
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    
    try:
        # åˆ›å»ºAutoencoderKL
        logger.info("åˆ›å»ºAutoencoderKL...")
        autoencoder = AutoencoderKL(
            spatial_dims=ae_config['spatial_dims'],
            in_channels=ae_config['in_channels'],
            out_channels=ae_config['out_channels'],
            num_channels=tuple(ae_config['num_channels']),
            latent_channels=ae_config['latent_channels'],
            num_res_blocks=ae_config['num_res_blocks'],
            norm_num_groups=ae_config.get('norm_num_groups', 16),
            attention_levels=tuple(ae_config['attention_levels']),
            downsample_factors=tuple(ae_config.get('downsample_factors', [2, 2])),
            initial_downsample_factor=ae_config.get('initial_downsample_factor', 1)
        )
        autoencoder.to(device)
        logger.info(f"âœ… AutoencoderKLåˆ›å»ºæˆåŠŸ")
        
        # è®¡ç®—å‚æ•°é‡
        total_params = sum(p.numel() for p in autoencoder.parameters())
        trainable_params = sum(p.numel() for p in autoencoder.parameters() if p.requires_grad)
        logger.info(f"   æ€»å‚æ•°é‡: {total_params:,}")
        logger.info(f"   å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
        
        # åˆ›å»ºåˆ¤åˆ«å™¨
        logger.info("åˆ›å»ºPatchDiscriminator...")
        disc_config = ae_config['training']['discriminator']
        discriminator = PatchDiscriminator(
            spatial_dims=ae_config['spatial_dims'],
            num_layers_d=disc_config['num_layers_d'],
            num_channels=disc_config['num_channels'],
            in_channels=ae_config['in_channels'],
            out_channels=ae_config['out_channels']
        )
        discriminator.to(device)
        logger.info(f"âœ… PatchDiscriminatoråˆ›å»ºæˆåŠŸ")
        
        disc_params = sum(p.numel() for p in discriminator.parameters())
        logger.info(f"   åˆ¤åˆ«å™¨å‚æ•°é‡: {disc_params:,}")
        
        return True, autoencoder, discriminator, device
        
    except Exception as e:
        logger.error(f"âŒ æ¨¡å‹åˆ›å»ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False, None, None, None


def test_forward_pass(autoencoder, discriminator, train_loader, device):
    """æµ‹è¯•å‰å‘ä¼ æ’­"""
    logger.info("\n" + "=" * 60)
    logger.info("æµ‹è¯•3: å‰å‘ä¼ æ’­")
    logger.info("=" * 60)
    
    try:
        # è·å–ä¸€ä¸ªbatch
        batch = next(iter(train_loader))
        images = batch["image"].to(device)
        
        logger.info(f"è¾“å…¥å›¾åƒå½¢çŠ¶: {images.shape}")
        
        # æµ‹è¯•Autoencoderå‰å‘ä¼ æ’­
        logger.info("æµ‹è¯•Autoencoderå‰å‘ä¼ æ’­...")
        autoencoder.eval()
        with torch.no_grad():
            reconstruction, z_mu, z_sigma = autoencoder(images)
        
        logger.info(f"âœ… Autoencoderå‰å‘ä¼ æ’­æˆåŠŸ")
        logger.info(f"   é‡å»ºå›¾åƒå½¢çŠ¶: {reconstruction.shape}")
        logger.info(f"   Latentå‡å€¼å½¢çŠ¶: {z_mu.shape}")
        logger.info(f"   Latentæ ‡å‡†å·®å½¢çŠ¶: {z_sigma.shape}")
        
        # è®¡ç®—é‡å»ºè¯¯å·®
        recon_error = torch.abs(reconstruction - images).mean().item()
        logger.info(f"   é‡å»ºè¯¯å·® (éšæœºåˆå§‹åŒ–): {recon_error:.4f}")
        
        # æµ‹è¯•Discriminatorå‰å‘ä¼ æ’­
        logger.info("æµ‹è¯•Discriminatorå‰å‘ä¼ æ’­...")
        discriminator.eval()
        with torch.no_grad():
            disc_out = discriminator(images)
        
        logger.info(f"âœ… Discriminatorå‰å‘ä¼ æ’­æˆåŠŸ")
        logger.info(f"   åˆ¤åˆ«å™¨è¾“å‡ºå±‚æ•°: {len(disc_out)}")
        logger.info(f"   æœ€ç»ˆè¾“å‡ºå½¢çŠ¶: {disc_out[-1].shape}")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ å‰å‘ä¼ æ’­å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_sliding_window_inference(autoencoder, device, config):
    """æµ‹è¯•æ»‘åŠ¨çª—å£æ¨ç†"""
    logger.info("\n" + "=" * 60)
    logger.info("æµ‹è¯•4: æ»‘åŠ¨çª—å£æ¨ç†")
    logger.info("=" * 60)
    
    try:
        # åˆ›å»ºä¸€ä¸ªå¤§çš„æµ‹è¯•ä½“ç§¯ï¼ˆæ¨¡æ‹Ÿ256Ã—256Ã—64ï¼‰
        large_volume = torch.randn(1, 1, 192, 192, 96).to(device)
        logger.info(f"åˆ›å»ºå¤§ä½“ç§¯ç”¨äºæµ‹è¯•: {large_volume.shape}")
        
        # åˆ›å»ºæ»‘åŠ¨çª—å£æ¨ç†å™¨
        roi_size = tuple(config['data']['voxel_size'])
        logger.info(f"ROIå¤§å° (è®­ç»ƒpatchå¤§å°): {roi_size}")
        
        inferer = AutoencoderSlidingWindowInferer(
            autoencoder=autoencoder,
            roi_size=roi_size,
            sw_batch_size=4,
            overlap=0.25
        )
        
        # æµ‹è¯•é‡å»º
        logger.info("ä½¿ç”¨æ»‘åŠ¨çª—å£è¿›è¡Œé‡å»º...")
        with torch.no_grad():
            reconstruction = inferer.reconstruct(large_volume)
        
        logger.info(f"âœ… æ»‘åŠ¨çª—å£æ¨ç†æˆåŠŸ")
        logger.info(f"   è¾“å‡ºå½¢çŠ¶: {reconstruction.shape}")
        logger.info(f"   å½¢çŠ¶æ˜¯å¦åŒ¹é…: {reconstruction.shape == large_volume.shape}")
        
        # æµ‹è¯•ç¼–ç 
        logger.info("æµ‹è¯•æ»‘åŠ¨çª—å£ç¼–ç ...")
        with torch.no_grad():
            z_mu, z_sigma = inferer.encode(large_volume)
        
        logger.info(f"âœ… æ»‘åŠ¨çª—å£ç¼–ç æˆåŠŸ")
        logger.info(f"   Latentå½¢çŠ¶: {z_mu.shape}")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ æ»‘åŠ¨çª—å£æ¨ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_memory_usage(autoencoder, discriminator, train_loader, device):
    """æµ‹è¯•æ˜¾å­˜å ç”¨"""
    logger.info("\n" + "=" * 60)
    logger.info("æµ‹è¯•5: æ˜¾å­˜å ç”¨")
    logger.info("=" * 60)
    
    if not torch.cuda.is_available():
        logger.info("âš ï¸ CUDAä¸å¯ç”¨ï¼Œè·³è¿‡æ˜¾å­˜æµ‹è¯•")
        return True
    
    try:
        # æ¸…ç©ºç¼“å­˜
        torch.cuda.empty_cache()
        torch.cuda.reset_peak_memory_stats()
        
        # è·å–ä¸€ä¸ªbatch
        batch = next(iter(train_loader))
        images = batch["image"].to(device)
        
        # æµ‹è¯•å‰å‘ä¼ æ’­çš„æ˜¾å­˜å ç”¨
        autoencoder.train()
        discriminator.train()
        
        # Generatorå‰å‘ä¼ æ’­
        reconstruction, z_mu, z_sigma = autoencoder(images)
        loss_g = torch.nn.functional.mse_loss(reconstruction, images)
        
        # Discriminatorå‰å‘ä¼ æ’­
        disc_out_fake = discriminator(reconstruction.detach())
        disc_out_real = discriminator(images)
        
        # è®°å½•å³°å€¼æ˜¾å­˜
        peak_memory_mb = torch.cuda.max_memory_allocated() / 1024 / 1024
        current_memory_mb = torch.cuda.memory_allocated() / 1024 / 1024
        
        logger.info(f"âœ… æ˜¾å­˜å ç”¨æµ‹è¯•å®Œæˆ")
        logger.info(f"   å³°å€¼æ˜¾å­˜: {peak_memory_mb:.1f} MB")
        logger.info(f"   å½“å‰æ˜¾å­˜: {current_memory_mb:.1f} MB")
        logger.info(f"   Batchå¤§å°: {images.shape[0]}")
        logger.info(f"   æ¯ä¸ªæ ·æœ¬æ˜¾å­˜: {peak_memory_mb / images.shape[0]:.1f} MB")
        
        # æ¸…ç†
        del reconstruction, z_mu, z_sigma, loss_g, disc_out_fake, disc_out_real
        torch.cuda.empty_cache()
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ æ˜¾å­˜æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """ä¸»æµ‹è¯•æµç¨‹"""
    logger.info("ğŸš€ å¼€å§‹æµ‹è¯•Patch-Basedè®­ç»ƒé…ç½®")
    logger.info("=" * 60)
    
    # é…ç½®æ–‡ä»¶è·¯å¾„
    config_path = "monai_diffusion/config/ldm_config_patched.yaml"
    
    if not Path(config_path).exists():
        logger.error(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
        return
    
    logger.info(f"é…ç½®æ–‡ä»¶: {config_path}\n")
    
    # åŠ è½½é…ç½®
    with open(config_path, 'r') as f:
        config = yaml.safe_load(f)
    
    # è®¾ç½®éšæœºç§å­
    set_determinism(config.get('seed', 42))
    
    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    results = {}
    
    # æµ‹è¯•1: æ•°æ®åŠ è½½
    success, train_loader, val_loader = test_data_loading(config_path)
    results['data_loading'] = success
    
    if not success:
        logger.error("\nâŒ æ•°æ®åŠ è½½æµ‹è¯•å¤±è´¥ï¼Œæ— æ³•ç»§ç»­åç»­æµ‹è¯•")
        logger.error("è¯·æ£€æŸ¥æ•°æ®è·¯å¾„æ˜¯å¦æ­£ç¡®ï¼Œæˆ–è€…è·³è¿‡æ­¤æµ‹è¯•è¿è¡Œå…¶ä»–æµ‹è¯•")
        # ä¸è¦å®Œå…¨é€€å‡ºï¼Œç»§ç»­æµ‹è¯•å…¶ä»–åŠŸèƒ½
        logger.info("\nç»§ç»­æµ‹è¯•æ¨¡å‹åˆ›å»ºï¼ˆä¸ä¾èµ–æ•°æ®ï¼‰...")
    
    # æµ‹è¯•2: æ¨¡å‹åˆ›å»º
    success, autoencoder, discriminator, device = test_model_creation(config_path)
    results['model_creation'] = success
    
    if not success:
        logger.error("\nâŒ æ¨¡å‹åˆ›å»ºæµ‹è¯•å¤±è´¥ï¼Œæ— æ³•ç»§ç»­åç»­æµ‹è¯•")
        return
    
    # å¦‚æœæ•°æ®åŠ è½½æˆåŠŸï¼Œç»§ç»­æµ‹è¯•
    if results['data_loading']:
        # æµ‹è¯•3: å‰å‘ä¼ æ’­
        success = test_forward_pass(autoencoder, discriminator, train_loader, device)
        results['forward_pass'] = success
        
        # æµ‹è¯•5: æ˜¾å­˜å ç”¨
        success = test_memory_usage(autoencoder, discriminator, train_loader, device)
        results['memory_usage'] = success
    else:
        logger.warning("âš ï¸ è·³è¿‡å‰å‘ä¼ æ’­å’Œæ˜¾å­˜æµ‹è¯•ï¼ˆæ•°æ®åŠ è½½å¤±è´¥ï¼‰")
        results['forward_pass'] = None
        results['memory_usage'] = None
    
    # æµ‹è¯•4: æ»‘åŠ¨çª—å£æ¨ç†ï¼ˆä¸ä¾èµ–çœŸå®æ•°æ®ï¼‰
    success = test_sliding_window_inference(autoencoder, device, config)
    results['sliding_window'] = success
    
    # æ€»ç»“
    logger.info("\n" + "=" * 60)
    logger.info("ğŸ“Š æµ‹è¯•æ€»ç»“")
    logger.info("=" * 60)
    
    for test_name, result in results.items():
        if result is True:
            status = "âœ… é€šè¿‡"
        elif result is False:
            status = "âŒ å¤±è´¥"
        else:
            status = "âš ï¸ è·³è¿‡"
        logger.info(f"{test_name:.<30} {status}")
    
    all_passed = all(r in [True, None] for r in results.values())
    
    if all_passed:
        logger.info("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼Patch-Basedè®­ç»ƒé…ç½®å¯ä»¥æ­£å¸¸ä½¿ç”¨ï¼")
        logger.info("\nä¸‹ä¸€æ­¥ï¼šè¿è¡Œè®­ç»ƒ")
        logger.info("python monai_diffusion/3d_ldm/train_autoencoder.py --config monai_diffusion/config/ldm_config_patched.yaml")
    else:
        logger.warning("\nâš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä¸Šé¢çš„é”™è¯¯ä¿¡æ¯")


if __name__ == "__main__":
    main()

