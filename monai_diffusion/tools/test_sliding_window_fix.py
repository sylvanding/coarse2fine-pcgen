"""
æµ‹è¯•æ»‘åŠ¨çª—å£æ¨ç†çš„bugä¿®å¤

éªŒè¯ï¼š
1. AutoencoderSlidingWindowInfererèƒ½å¤Ÿæ­£ç¡®æ¨ç†
2. visualize_reconstructionå‡½æ•°èƒ½å¤Ÿä½¿ç”¨æ»‘åŠ¨çª—å£æ¨ç†
"""

import sys
from pathlib import Path
import logging

# æ·»åŠ GenerativeModelså’Œé¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root / "GenerativeModels"))
sys.path.insert(0, str(project_root))

import torch
import numpy as np
from generative.networks.nets import AutoencoderKL
from monai_diffusion.utils.sliding_window_inference import AutoencoderSlidingWindowInferer

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def test_sliding_window_basic():
    """æµ‹è¯•åŸºæœ¬çš„æ»‘åŠ¨çª—å£æ¨ç†åŠŸèƒ½"""
    logger.info("=" * 80)
    logger.info("æµ‹è¯•1: åŸºæœ¬æ»‘åŠ¨çª—å£æ¨ç†")
    logger.info("=" * 80)
    
    # åˆ›å»ºå°å‹AutoencoderKLï¼ˆé¿å…æ˜¾å­˜ä¸è¶³ï¼‰
    autoencoder = AutoencoderKL(
        spatial_dims=3,
        in_channels=1,
        out_channels=1,
        num_channels=(16, 32, 64),
        latent_channels=3,
        num_res_blocks=1,
        norm_num_groups=8,
        attention_levels=(False, False, True),
    )
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    autoencoder.to(device)
    autoencoder.eval()
    
    logger.info(f"ä½¿ç”¨è®¾å¤‡: {device}")
    logger.info(f"æ¨¡å‹å‚æ•°æ•°é‡: {sum(p.numel() for p in autoencoder.parameters()):,}")
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®ï¼ˆæ¨¡æ‹Ÿ128Ã—128Ã—64çš„ä½“ç§¯ï¼‰
    full_volume = torch.randn(1, 1, 128, 128, 64).to(device)
    logger.info(f"è¾“å…¥å½¢çŠ¶: {full_volume.shape}")
    
    # åˆ›å»ºæ»‘åŠ¨çª—å£æ¨ç†å™¨ï¼ˆä½¿ç”¨64Ã—64Ã—32çš„ROIï¼‰
    inferer = AutoencoderSlidingWindowInferer(
        autoencoder=autoencoder,
        roi_size=(64, 64, 32),
        sw_batch_size=4,
        overlap=0.25,
        mode="gaussian"
    )
    
    # æµ‹è¯•é‡å»º
    logger.info("æ‰§è¡Œæ»‘åŠ¨çª—å£é‡å»º...")
    with torch.no_grad():
        reconstruction = inferer.reconstruct(full_volume, return_latent=False)
    
    logger.info(f"é‡å»ºå½¢çŠ¶: {reconstruction.shape}")
    logger.info(f"é‡å»ºè¯¯å·® (MAE): {torch.abs(reconstruction - full_volume).mean().item():.6f}")
    
    # æµ‹è¯•å¸¦latentçš„é‡å»º
    logger.info("\næ‰§è¡Œæ»‘åŠ¨çª—å£é‡å»ºï¼ˆè¿”å›latentï¼‰...")
    with torch.no_grad():
        reconstruction2, z_mu, z_sigma = inferer.reconstruct(full_volume, return_latent=True)
    
    logger.info(f"é‡å»ºå½¢çŠ¶: {reconstruction2.shape}")
    logger.info(f"Latentå‡å€¼å½¢çŠ¶: {z_mu.shape}")
    logger.info(f"Latentæ ‡å‡†å·®å½¢çŠ¶: {z_sigma.shape}")
    
    # æµ‹è¯•ç¼–ç 
    logger.info("\næ‰§è¡Œæ»‘åŠ¨çª—å£ç¼–ç ...")
    with torch.no_grad():
        z_mu2, z_sigma2 = inferer.encode(full_volume)
    
    logger.info(f"ç¼–ç åLatentå‡å€¼å½¢çŠ¶: {z_mu2.shape}")
    logger.info(f"ç¼–ç åLatentæ ‡å‡†å·®å½¢çŠ¶: {z_sigma2.shape}")
    
    logger.info("\nâœ… æµ‹è¯•1é€šè¿‡ï¼æ»‘åŠ¨çª—å£æ¨ç†åŠŸèƒ½æ­£å¸¸")
    return True


def test_sliding_window_comparison():
    """æµ‹è¯•æ»‘åŠ¨çª—å£æ¨ç†ä¸ç›´æ¥æ¨ç†çš„å¯¹æ¯”"""
    logger.info("\n" + "=" * 80)
    logger.info("æµ‹è¯•2: æ»‘åŠ¨çª—å£æ¨ç† vs ç›´æ¥æ¨ç†")
    logger.info("=" * 80)
    
    # åˆ›å»ºAutoencoderKL
    autoencoder = AutoencoderKL(
        spatial_dims=3,
        in_channels=1,
        out_channels=1,
        num_channels=(16, 32),
        latent_channels=3,
        num_res_blocks=1,
        norm_num_groups=8,
        attention_levels=(False, False),
    )
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    autoencoder.to(device)
    autoencoder.eval()
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®ï¼ˆè¾ƒå°çš„ä½“ç§¯ï¼Œæ–¹ä¾¿ç›´æ¥æ¨ç†å¯¹æ¯”ï¼‰
    test_volume = torch.randn(1, 1, 64, 64, 32).to(device)
    logger.info(f"æµ‹è¯•ä½“ç§¯å½¢çŠ¶: {test_volume.shape}")
    
    # æ–¹å¼1: ç›´æ¥æ¨ç†
    logger.info("\næ–¹å¼1: ç›´æ¥æ¨ç†")
    with torch.no_grad():
        recon_direct, _, _ = autoencoder(test_volume)
    logger.info(f"ç›´æ¥é‡å»ºå½¢çŠ¶: {recon_direct.shape}")
    
    # æ–¹å¼2: æ»‘åŠ¨çª—å£æ¨ç†ï¼ˆä½¿ç”¨ç›¸åŒå¤§å°çš„ROIï¼‰
    logger.info("\næ–¹å¼2: æ»‘åŠ¨çª—å£æ¨ç†ï¼ˆROIä¸è¾“å…¥ç›¸åŒï¼‰")
    inferer = AutoencoderSlidingWindowInferer(
        autoencoder=autoencoder,
        roi_size=(64, 64, 32),
        sw_batch_size=1,
        overlap=0.0,  # æ— é‡å 
        mode="constant"
    )
    
    with torch.no_grad():
        recon_sw = inferer.reconstruct(test_volume)
    logger.info(f"æ»‘åŠ¨çª—å£é‡å»ºå½¢çŠ¶: {recon_sw.shape}")
    
    # å¯¹æ¯”ä¸¤ç§æ–¹æ³•çš„å·®å¼‚
    diff = torch.abs(recon_direct - recon_sw)
    logger.info(f"\nä¸¤ç§æ–¹æ³•çš„å·®å¼‚:")
    logger.info(f"  å¹³å‡ç»å¯¹è¯¯å·®: {diff.mean().item():.6f}")
    logger.info(f"  æœ€å¤§ç»å¯¹è¯¯å·®: {diff.max().item():.6f}")
    
    # ç”±äºROIå¤§å°ä¸è¾“å…¥ç›¸åŒä¸”æ— é‡å ï¼Œä¸¤ç§æ–¹æ³•åº”è¯¥äº§ç”Ÿå‡ ä¹ç›¸åŒçš„ç»“æœ
    if diff.mean().item() < 1e-5:
        logger.info("\nâœ… æµ‹è¯•2é€šè¿‡ï¼æ»‘åŠ¨çª—å£æ¨ç†ä¸ç›´æ¥æ¨ç†ç»“æœä¸€è‡´")
        return True
    else:
        logger.warning("\nâš ï¸ è­¦å‘Šï¼šæ»‘åŠ¨çª—å£æ¨ç†ä¸ç›´æ¥æ¨ç†å­˜åœ¨å·®å¼‚ï¼ˆè¿™åœ¨ä½¿ç”¨é‡å æ—¶æ˜¯æ­£å¸¸çš„ï¼‰")
        return True


def test_patch_based_simulation():
    """æ¨¡æ‹Ÿpatch-basedè®­ç»ƒåœºæ™¯"""
    logger.info("\n" + "=" * 80)
    logger.info("æµ‹è¯•3: Patch-Basedè®­ç»ƒåœºæ™¯æ¨¡æ‹Ÿ")
    logger.info("=" * 80)
    
    # åˆ›å»ºAutoencoderKL
    autoencoder = AutoencoderKL(
        spatial_dims=3,
        in_channels=1,
        out_channels=1,
        num_channels=(16, 32, 64),
        latent_channels=3,
        num_res_blocks=1,
        norm_num_groups=8,
        attention_levels=(False, False, True),
    )
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    autoencoder.to(device)
    autoencoder.eval()
    
    # åœºæ™¯ï¼šè®­ç»ƒæ—¶ä½¿ç”¨96Ã—96Ã—48çš„patch
    train_patch_size = (96, 96, 48)
    logger.info(f"è®­ç»ƒpatchå¤§å°: {train_patch_size}")
    
    # æ¨ç†æ—¶å¤„ç†256Ã—256Ã—64çš„å®Œæ•´ä½“ç§¯
    full_size = (256, 256, 64)
    logger.info(f"å®Œæ•´ä½“ç§¯å¤§å°: {full_size}")
    
    # åˆ›å»ºå®Œæ•´ä½“ç§¯æ•°æ®
    full_volume = torch.randn(1, 1, *full_size).to(device)
    
    # ä½¿ç”¨æ»‘åŠ¨çª—å£æ¨ç†
    logger.info(f"\nä½¿ç”¨æ»‘åŠ¨çª—å£æ¨ç†å¤„ç†å®Œæ•´ä½“ç§¯...")
    logger.info(f"  ROIå¤§å°: {train_patch_size} (ä¸è®­ç»ƒpatchä¸€è‡´)")
    logger.info(f"  é‡å æ¯”ä¾‹: 0.25")
    
    inferer = AutoencoderSlidingWindowInferer(
        autoencoder=autoencoder,
        roi_size=train_patch_size,
        sw_batch_size=4,
        overlap=0.25,
        mode="gaussian"
    )
    
    with torch.no_grad():
        reconstruction = inferer.reconstruct(full_volume)
    
    logger.info(f"\né‡å»ºå®Œæˆ!")
    logger.info(f"  è¾“å…¥å½¢çŠ¶: {full_volume.shape}")
    logger.info(f"  è¾“å‡ºå½¢çŠ¶: {reconstruction.shape}")
    logger.info(f"  é‡å»ºè¯¯å·®: {torch.abs(reconstruction - full_volume).mean().item():.6f}")
    
    # è®¡ç®—æ˜¾å­˜ä½¿ç”¨æƒ…å†µï¼ˆå¦‚æœåœ¨GPUä¸Šï¼‰
    if torch.cuda.is_available():
        memory_allocated = torch.cuda.max_memory_allocated() / 1024**3
        logger.info(f"\næ˜¾å­˜ä½¿ç”¨å³°å€¼: {memory_allocated:.2f} GB")
    
    logger.info("\nâœ… æµ‹è¯•3é€šè¿‡ï¼Patch-basedåœºæ™¯æ¨¡æ‹ŸæˆåŠŸ")
    return True


def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    logger.info("å¼€å§‹æµ‹è¯•æ»‘åŠ¨çª—å£æ¨ç†bugä¿®å¤...")
    
    try:
        # æµ‹è¯•1: åŸºæœ¬åŠŸèƒ½
        test_sliding_window_basic()
        
        # æµ‹è¯•2: å¯¹æ¯”
        test_sliding_window_comparison()
        
        # æµ‹è¯•3: Patch-basedåœºæ™¯
        test_patch_based_simulation()
        
        logger.info("\n" + "=" * 80)
        logger.info("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ»‘åŠ¨çª—å£æ¨ç†åŠŸèƒ½æ­£å¸¸å·¥ä½œ")
        logger.info("=" * 80)
        
    except Exception as e:
        logger.error(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return False
    
    return True


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)

