---
globs: src/models/*.py,**/train_*.py,**/model_*.py
description: 深度学习模型开发规范
---

# 深度学习模型开发规范

## 模型架构设计

### 基础模型结构
```python
import torch
import torch.nn as nn

class VoxelGenerator(nn.Module):
    """
    体素生成网络
    
    基于VAE/GAN/Diffusion的3D体素生成模型，用于生成高质量的
    体素表示，作为点云生成的中间步骤。
    """
    
    def __init__(self, latent_dim: int = 256, voxel_size: int = 64):
        super().__init__()
        self.latent_dim = latent_dim
        self.voxel_size = voxel_size
        
        # 模型层定义...
        
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """
        前向传播
        
        Args:
            x: 输入张量，shape取决于模型类型
            
        Returns:
            生成的体素网格，shape为(batch_size, 1, voxel_size, voxel_size, voxel_size)
        """
        pass
```

### 点云精细化网络
```python
class PointRefiner(nn.Module):
    """
    基于PointNet++的点云精细化网络
    
    对从体素采样得到的粗糙点云进行逐点精细化，
    提升生成点云的质量和细节。
    """
    
    def __init__(self, input_channels: int = 3, output_channels: int = 3):
        super().__init__()
        # PointNet++组件...
        
    def forward(self, points: torch.Tensor) -> torch.Tensor:
        """
        点云精细化前向传播
        
        Args:
            points: 粗糙点云，shape为(batch_size, num_points, 3)
            
        Returns:
            精细化后的点云，shape为(batch_size, num_points, 3)
        """
        pass
```

## 训练流程规范

### 训练脚本结构
```python
# scripts/train_voxel_generator.py
def main():
    """主训练流程"""
    # 1. 参数解析
    args = parse_arguments()
    
    # 2. 设备配置
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # 3. 数据加载
    train_loader, val_loader = create_data_loaders(args)
    
    # 4. 模型初始化
    model = VoxelGenerator(args.latent_dim, args.voxel_size).to(device)
    
    # 5. 优化器和损失函数
    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)
    criterion = create_loss_function(args.loss_type)
    
    # 6. 训练循环
    for epoch in range(args.epochs):
        train_loss = train_epoch(model, train_loader, optimizer, criterion, device)
        val_loss = validate_epoch(model, val_loader, criterion, device)
        
        # 7. 保存检查点
        save_checkpoint(model, optimizer, epoch, val_loss, args.checkpoint_dir)
        
        # 8. 早停和学习率调度
        if should_stop_early(val_loss):
            break
```

### 训练配置管理
```python
# 使用配置文件管理超参数
@dataclass
class TrainingConfig:
    # 模型参数
    latent_dim: int = 256
    voxel_size: int = 64
    
    # 训练参数
    batch_size: int = 32
    learning_rate: float = 1e-4
    epochs: int = 1000
    
    # 数据参数
    data_path: str = "data/processed/"
    train_ratio: float = 0.8
    
    # 输出参数
    checkpoint_dir: str = "checkpoints/"
    log_dir: str = "logs/"
```

## 损失函数设计

### 体素生成损失
```python
class VoxelGenerationLoss(nn.Module):
    """体素生成专用损失函数"""
    
    def __init__(self, recon_weight: float = 1.0, kl_weight: float = 0.1):
        super().__init__()
        self.recon_weight = recon_weight
        self.kl_weight = kl_weight
        
    def forward(self, pred_voxels, target_voxels, mu=None, logvar=None):
        # 重建损失（二值交叉熵或MSE）
        recon_loss = F.binary_cross_entropy_with_logits(pred_voxels, target_voxels)
        
        # KL散度损失（用于VAE）
        kl_loss = 0
        if mu is not None and logvar is not None:
            kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())
            
        return self.recon_weight * recon_loss + self.kl_weight * kl_loss
```

### 点云精细化损失
```python
class PointRefinementLoss(nn.Module):
    """点云精细化损失函数"""
    
    def __init__(self, chamfer_weight: float = 1.0, normal_weight: float = 0.1):
        super().__init__()
        self.chamfer_weight = chamfer_weight
        self.normal_weight = normal_weight
        
    def chamfer_distance(self, pred_points, target_points):
        """计算Chamfer距离"""
        # 实现双向最近邻距离
        pass
        
    def normal_consistency_loss(self, pred_points, target_points):
        """法向量一致性损失"""
        # 计算表面法向量的一致性
        pass
```

## 数据加载和预处理

### 数据集类设计
```python
class PointCloudVoxelDataset(torch.utils.data.Dataset):
    """点云-体素对数据集"""
    
    def __init__(self, data_dir: str, voxel_size: int = 64, transform=None):
        self.data_dir = data_dir
        self.voxel_size = voxel_size
        self.transform = transform
        
        # 加载数据索引
        self.data_list = self._load_data_list()
        
    def __getitem__(self, idx):
        # 加载点云数据
        point_cloud = self._load_point_cloud(idx)
        
        # 转换为体素
        voxel_grid = self._point_cloud_to_voxel(point_cloud)
        
        if self.transform:
            point_cloud, voxel_grid = self.transform(point_cloud, voxel_grid)
            
        return {
            'point_cloud': torch.from_numpy(point_cloud).float(),
            'voxel_grid': torch.from_numpy(voxel_grid).float()
        }
```

### 数据增强
```python
class VoxelAugmentation:
    """体素数据增强"""
    
    def __init__(self, rotation_prob: float = 0.5, flip_prob: float = 0.3):
        self.rotation_prob = rotation_prob
        self.flip_prob = flip_prob
        
    def __call__(self, point_cloud, voxel_grid):
        # 随机旋转
        if np.random.rand() < self.rotation_prob:
            angle = np.random.uniform(0, 2 * np.pi)
            point_cloud, voxel_grid = self._rotate(point_cloud, voxel_grid, angle)
            
        # 随机翻转
        if np.random.rand() < self.flip_prob:
            point_cloud, voxel_grid = self._flip(point_cloud, voxel_grid)
            
        return point_cloud, voxel_grid
```

## 模型评估指标

### 体素生成评估
```python
def evaluate_voxel_generation(model, data_loader, device):
    """评估体素生成质量"""
    model.eval()
    
    metrics = {
        'iou': [],  # 交并比
        'dice': [], # Dice系数
        'hausdorff': []  # Hausdorff距离
    }
    
    with torch.no_grad():
        for batch in data_loader:
            pred_voxels = model(batch['input'].to(device))
            target_voxels = batch['target'].to(device)
            
            # 计算各种指标
            iou = compute_iou(pred_voxels, target_voxels)
            dice = compute_dice(pred_voxels, target_voxels)
            hausdorff = compute_hausdorff_distance(pred_voxels, target_voxels)
            
            metrics['iou'].append(iou)
            metrics['dice'].append(dice)
            metrics['hausdorff'].append(hausdorff)
    
    return {k: np.mean(v) for k, v in metrics.items()}
```

### 点云生成评估
```python
def evaluate_point_cloud_generation(generated_clouds, reference_clouds):
    """评估点云生成质量"""
    metrics = {}
    
    # Chamfer距离
    metrics['chamfer_distance'] = compute_chamfer_distance(generated_clouds, reference_clouds)
    
    # Earth Mover's距离
    metrics['emd'] = compute_earth_movers_distance(generated_clouds, reference_clouds)
    
    # 覆盖率和MMD
    metrics['coverage'] = compute_coverage(generated_clouds, reference_clouds)
    metrics['mmd'] = compute_mmd(generated_clouds, reference_clouds)
    
    return metrics
```

## 模型保存和加载

### 检查点管理
```python
def save_checkpoint(model, optimizer, epoch, loss, checkpoint_dir):
    """保存训练检查点"""
    checkpoint = {
        'epoch': epoch,
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
        'loss': loss,
        'timestamp': datetime.now().isoformat()
    }
    
    # 保存最新检查点
    torch.save(checkpoint, os.path.join(checkpoint_dir, 'latest.pth'))
    
    # 保存最佳模型
    if is_best_model(loss):
        torch.save(checkpoint, os.path.join(checkpoint_dir, 'best.pth'))

def load_checkpoint(model, optimizer, checkpoint_path):
    """加载训练检查点"""
    checkpoint = torch.load(checkpoint_path)
    
    model.load_state_dict(checkpoint['model_state_dict'])
    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
    
    return checkpoint['epoch'], checkpoint['loss']
```

## GPU内存管理

```python
def optimize_gpu_memory():
    """GPU内存优化策略"""
    # 清理缓存
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
    
    # 使用梯度检查点
    torch.utils.checkpoint.checkpoint_sequential()
    
    # 混合精度训练
    scaler = torch.cuda.amp.GradScaler()
    
    # 批次大小自适应
    def find_optimal_batch_size(model, data_loader):
        for batch_size in [64, 32, 16, 8, 4, 2, 1]:
            try:
                # 尝试训练一个batch
                test_batch = next(iter(data_loader))
                with torch.cuda.amp.autocast():
                    output = model(test_batch)
                    loss = criterion(output, target)
                loss.backward()
                return batch_size
            except RuntimeError as e:
                if "out of memory" in str(e):
                    torch.cuda.empty_cache()
                    continue
                raise e
```