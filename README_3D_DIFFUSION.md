# 3D Diffusion ä½“ç´ ç”Ÿæˆæ¨¡å‹

åŸºäºDDPM (Denoising Diffusion Probabilistic Models) çš„3Dä½“ç´ ç”Ÿæˆç³»ç»Ÿï¼Œä½¿ç”¨PyTorch Lightningæ¡†æ¶å®ç°ã€‚

## ğŸŒŸ ç‰¹æ€§

- **3D UNetæ¶æ„**: ä¸“ä¸ºä½“ç´ æ•°æ®è®¾è®¡çš„3Då·ç§¯ç¥ç»ç½‘ç»œ
- **DDPMæ‰©æ•£è¿‡ç¨‹**: é«˜è´¨é‡çš„ç”Ÿæˆå¼å»ºæ¨¡
- **DDIMé‡‡æ ·**: å¿«é€Ÿç¡®å®šæ€§é‡‡æ ·æ”¯æŒ
- **å¯é…ç½®ä½“ç´ å¤§å°**: æ”¯æŒ32Â³, 64Â³, 128Â³ç­‰åˆ†è¾¨ç‡
- **è‡ªåŠ¨éªŒè¯**: æ¯Nä¸ªepochè‡ªåŠ¨ç”ŸæˆéªŒè¯æ ·æœ¬å¹¶ä¿å­˜TIFF
- **PyTorch Lightning**: ç°ä»£åŒ–è®­ç»ƒæ¡†æ¶
- **é…ç½®é©±åŠ¨**: YAMLé…ç½®æ–‡ä»¶ç³»ç»Ÿ
- **EMAæ”¯æŒ**: æŒ‡æ•°ç§»åŠ¨å¹³å‡æå‡ç”Ÿæˆè´¨é‡

## ğŸ“‹ ç³»ç»Ÿè¦æ±‚

### ç¡¬ä»¶è¦æ±‚
- **GPU**: 8GB+ VRAM (64Â³ä½“ç´ ) / 4GB+ (32Â³ä½“ç´ )
- **å†…å­˜**: 16GB+ RAM
- **å­˜å‚¨**: 10GB+ å¯ç”¨ç©ºé—´

### è½¯ä»¶ä¾èµ–
```bash
# æ ¸å¿ƒä¾èµ–
torch>=1.12.0
pytorch-lightning>=1.8.0
numpy>=1.21.0
h5py>=3.7.0
tifffile>=2022.5.4
scipy>=1.9.0
PyYAML>=6.0
tqdm>=4.64.0

# å¯é€‰ä¾èµ– (æ¨è)
tensorboard>=2.9.0
matplotlib>=3.5.0
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒè®¾ç½®
```bash
# å…‹éš†é¡¹ç›®
cd /repos/coarse2fine-pcgen

# å®‰è£…ä¾èµ–
pip install torch pytorch-lightning numpy h5py tifffile scipy PyYAML tqdm

# æ£€æŸ¥ç³»ç»Ÿ
python scripts/run_example.py --check-deps --test-system
```

### 2. æ•°æ®å‡†å¤‡
ç¡®ä¿æ‚¨çš„æ•°æ®ä¸ºHDF5æ ¼å¼ï¼Œç»“æ„å¦‚ä¸‹ï¼š
```
data.h5
â”œâ”€â”€ point_clouds: (N, M, 3)  # Nä¸ªæ ·æœ¬ï¼Œæ¯ä¸ªMä¸ªç‚¹ï¼Œxyzåæ ‡
```

ç¤ºä¾‹æ•°æ®åˆ›å»ºï¼š
```bash
python scripts/test_conversion/create_sample_data.py
```

### 3. é…ç½®æ¨¡å‹
ç¼–è¾‘ `configs/diffusion_config.yaml`ï¼š
```yaml
data:
  h5_file_path: "/path/to/your/data.h5"
  voxel_size: 64
  voxelization_method: "gaussian"

model:
  model_channels: 128
  num_timesteps: 1000

training:
  batch_size: 4
  learning_rate: 0.0001
  max_epochs: 200
```

### 4. å¼€å§‹è®­ç»ƒ
```bash
# åŸºç¡€è®­ç»ƒ
python scripts/train_diffusion.py --config configs/diffusion_config.yaml

# è‡ªå®šä¹‰å‚æ•°
python scripts/train_diffusion.py \
  --data-path /path/to/data.h5 \
  --voxel-size 64 \
  --batch-size 4 \
  --max-epochs 100
```

### 5. ç”Ÿæˆæ ·æœ¬
```bash
# ä»æ£€æŸ¥ç‚¹ç”Ÿæˆæ ·æœ¬
python scripts/generate_samples.py \
  experiments/3d_diffusion_voxels/version_0/checkpoints/best-epoch=XX-val_loss=X.XXXX.ckpt \
  --num-samples 8 \
  --output-dir generated_samples
```

## ğŸ“Š æ•°æ®æµç¨‹

```
ç‚¹äº‘æ•°æ® â†’ ä½“ç´ åŒ– â†’ 3D Diffusionè®­ç»ƒ â†’ ç”Ÿæˆä½“ç´  â†’ (å¯é€‰)è½¬æ¢å›ç‚¹äº‘
   â†“           â†“            â†“              â†“
 H5æ–‡ä»¶    64Â³ä½“ç´ ç½‘æ ¼   UNetå™ªå£°é¢„æµ‹    TIFFæ–‡ä»¶
```

### ä½“ç´ åŒ–æ–¹æ³•
- **occupancy**: äºŒå€¼å æœ‰ç½‘æ ¼ (0/1)
- **density**: å¯†åº¦ç½‘æ ¼ (ç‚¹æ•°ç»Ÿè®¡)
- **gaussian**: é«˜æ–¯å¯†åº¦åˆ†å¸ƒ (æ¨è)

## ğŸ”§ é…ç½®è¯¦è§£

### å…³é”®é…ç½®é¡¹
| é…ç½®é¡¹ | è¯´æ˜ | æ¨èå€¼ |
|--------|------|---------|
| `data.voxel_size` | ä½“ç´ åˆ†è¾¨ç‡ | 64 |
| `data.voxelization_method` | ä½“ç´ åŒ–æ–¹æ³• | gaussian |
| `model.model_channels` | æ¨¡å‹åŸºç¡€é€šé“ | 128 |
| `training.batch_size` | æ‰¹æ¬¡å¤§å° | 4-8 |
| `training.learning_rate` | å­¦ä¹ ç‡ | 1e-4 |
| `validation.sample_interval` | éªŒè¯é—´éš” | 10 |

### ç¯å¢ƒå˜é‡è¦†ç›–
```bash
export DIFFUSION_DATA_VOXEL_SIZE=128
export DIFFUSION_TRAINING_BATCH_SIZE=2
export DIFFUSION_MODEL_MODEL_CHANNELS=64
```

## ğŸ“ˆ è®­ç»ƒç›‘æ§

### TensorBoard
```bash
tensorboard --logdir experiments/3d_diffusion_voxels/version_0/logs
```

### å…³é”®æŒ‡æ ‡
- **train_loss**: è®­ç»ƒæŸå¤±
- **val_loss**: éªŒè¯æŸå¤±
- **gen_occupancy**: ç”Ÿæˆä½“ç´ å æœ‰ç‡
- **learning_rate**: å­¦ä¹ ç‡å˜åŒ–

## ğŸ’¡ ä¼˜åŒ–å»ºè®®

### å†…å­˜ä¼˜åŒ–
```yaml
# å‡å°‘æ‰¹æ¬¡å¤§å°
training:
  batch_size: 2
  accumulate_grad_batches: 2  # ç­‰æ•ˆbatch_size=4

# ä½¿ç”¨æ··åˆç²¾åº¦
system:
  precision: "16-mixed"

# å‡å°‘å·¥ä½œè¿›ç¨‹
system:
  num_workers: 2
```

### æ€§èƒ½ä¼˜åŒ–
```yaml
# å¯ç”¨æ¨¡å‹ç¼–è¯‘ (PyTorch 2.0+)
model:
  compile_model: true

# æ•°æ®ç¼“å­˜
data:
  cache_voxels: true
  max_cache_size: 1000

# æŒä¹…åŒ–å·¥ä½œè¿›ç¨‹
system:
  persistent_workers: true
```

## ğŸ› è°ƒè¯•æŒ‡å—

### å¸¸è§é—®é¢˜
1. **å†…å­˜ä¸è¶³**: å‡å°‘batch_sizeæˆ–voxel_size
2. **è®­ç»ƒæ…¢**: æ£€æŸ¥GPUä½¿ç”¨ç‡ï¼Œå¯ç”¨æ··åˆç²¾åº¦
3. **ç”Ÿæˆè´¨é‡å·®**: å¢åŠ è®­ç»ƒæ—¶é—´ï¼Œè°ƒæ•´å­¦ä¹ ç‡
4. **éªŒè¯TIFFä¸ºç©º**: æ£€æŸ¥ä½“ç´ åŒ–å‚æ•°å’Œæ•°æ®è´¨é‡

### è°ƒè¯•æ¨¡å¼
```bash
# å¿«é€Ÿæµ‹è¯•æ¨¡å¼
python scripts/train_diffusion.py --fast-dev-run

# è¿‡æ‹Ÿåˆå°‘é‡æ•°æ®
python scripts/train_diffusion.py --overfit-batches 5

# é™åˆ¶è®­ç»ƒæ•°æ®
python scripts/train_diffusion.py --limit-train-batches 0.1
```

## ğŸ“ è¾“å‡ºæ–‡ä»¶

è®­ç»ƒè¿‡ç¨‹ä¸­ä¼šç”Ÿæˆä»¥ä¸‹æ–‡ä»¶ï¼š
```
experiments/3d_diffusion_voxels/version_0/
â”œâ”€â”€ checkpoints/              # æ¨¡å‹æ£€æŸ¥ç‚¹
â”‚   â”œâ”€â”€ best-epoch=XX-val_loss=X.XXXX.ckpt
â”‚   â””â”€â”€ last.ckpt
â”œâ”€â”€ logs/                     # TensorBoardæ—¥å¿—
â”œâ”€â”€ validation_outputs/       # éªŒè¯TIFFæ–‡ä»¶
â”‚   â”œâ”€â”€ epoch_0010/
â”‚   â”œâ”€â”€ epoch_0020/
â”‚   â””â”€â”€ ...
â””â”€â”€ config.yaml              # å®é™…ä½¿ç”¨çš„é…ç½®
```

## ğŸ”„ åç»­å¤„ç†

### ä½“ç´ åˆ°ç‚¹äº‘è½¬æ¢
ç”Ÿæˆä½“ç´ åå¯è½¬æ¢å›ç‚¹äº‘ï¼š
```python
from src.voxel.converter import PointCloudToVoxel

converter = PointCloudToVoxel(voxel_size=64)
point_cloud = converter.voxel_to_points(
    voxel_grid, 
    threshold=0.5, 
    method='probabilistic'
)
```

## ğŸ“š æŠ€æœ¯ç»†èŠ‚

### æ¨¡å‹æ¶æ„
- **ç¼–ç å™¨**: 3Då·ç§¯ä¸‹é‡‡æ ·ï¼Œé€šé“æ•°é€’å¢
- **è§£ç å™¨**: 3Dè½¬ç½®å·ç§¯ä¸Šé‡‡æ ·ï¼Œè·³è·ƒè¿æ¥
- **æ³¨æ„åŠ›**: å¤šå°ºåº¦è‡ªæ³¨æ„åŠ›æœºåˆ¶
- **æ—¶é—´åµŒå…¥**: æ­£å¼¦ä½ç½®ç¼–ç  + MLP

### æ‰©æ•£è¿‡ç¨‹
- **å‰å‘è¿‡ç¨‹**: é€æ­¥æ·»åŠ é«˜æ–¯å™ªå£°
- **åå‘è¿‡ç¨‹**: UNeté¢„æµ‹å™ªå£°
- **æŸå¤±å‡½æ•°**: MSEå™ªå£°é¢„æµ‹æŸå¤±
- **é‡‡æ ·**: DDIMç¡®å®šæ€§é‡‡æ ·

### æ•°æ®å¤„ç†
- **å½’ä¸€åŒ–**: ä½“ç´ å€¼æ˜ å°„åˆ°[-1,1]
- **å¢å¼º**: æ—‹è½¬ã€ç¿»è½¬ã€å™ªå£°
- **ç¼“å­˜**: å†…å­˜ç¼“å­˜åŠ é€Ÿè®­ç»ƒ

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤Issueå’ŒPull Requestæ¥æ”¹è¿›è¿™ä¸ªé¡¹ç›®ï¼

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®åŸºäºMITè®¸å¯è¯å¼€æºã€‚
